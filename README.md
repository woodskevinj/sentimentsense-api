# ğŸ’¬ SentimentSense API â€“ Real-Time Sentiment Analysis

A lightweight **FastAPI-based sentiment analysis microservice** that classifies text as Positive, Negative, or Neutral using a hybrid NLP approach â€” combining a rule-based sentiment layer with a trained Logistic Regression model.

---

## ğŸ§© Project Overview

SentimentSense API enables developers and businesses to analyze customer feedback, reviews, or social media text instantly through a RESTful endpoint.

The system includes:

- Text preprocessing (tokenization, stopword removal, lemmatization)
- Hybrid sentiment logic (keyword rules + trained model)
- Real-time inference via FastAPI
- Optional Docker and AWS ECS deployment

---

## ğŸ§  Tech Stack

| Component     | Technology                  |
| ------------- | --------------------------- |
| Language      | Python 3.9+                 |
| Framework     | FastAPI                     |
| NLP           | scikit-learn + NLTK         |
| Model Serving | joblib + FastAPI            |
| Deployment    | Docker / AWS ECS (optional) |

---

## âš™ï¸ Quick Start

```bash
# 1ï¸âƒ£ Create and activate venv
python -m venv venv
source venv/bin/activate  # Mac/Linux
pip install -r requirements.txt

# 2ï¸âƒ£ Train model
python src/train_model.py

# 3ï¸âƒ£ Run API
uvicorn app:app --reload
```

## ğŸ§ª Example Predictions

```bash
curl -X POST "http://127.0.0.1:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"text": "I absolutely love this project!"}'
```

Expected response:

```json
{ "sentiment": "positive" }
```

---

## ğŸ”— API Endpoints

### **1ï¸âƒ£ `/predict` â€” Sentiment Inference**

**Method:** `POST`
**Description:** Classifies input text as Positive, Negative, or Neutral using the hybrid sentiment model.

```bash
curl -X POST "http://127.0.0.1:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"text": "I absolutely love this project!"}'
```

- Response:

```json
{ "sentiment": "positive" }
```

### **2ï¸âƒ£ `/logs` â€” View Recent Predictions**

**Method:** `GET`
**Query Param:** limit (optional, default=10)
**Description:** Returns the most recent logged predictions from logs/sentiments.log.

```bash
curl "http://127.0.0.1:8000/logs?limit=5"
```

- Response:

```json
{
  "recent_sentiments": [
    "2025-10-28 22:10:43 | Text: I love this project! | Sentiment: positive",
    "2025-10-28 22:12:17 | Text: This is awful | Sentiment: negative"
  ]
}
```

### **3ï¸âƒ£ `/health` â€” API + Model Readiness**

**Method:** `GET`
**Description:** Confirms that the API, model, and vectorizer are loaded correctly â€” useful for ECS or uptime monitoring.

```bash
curl http://127.0.0.1:8000/health
```

- Response:

```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_file_exists": true,
  "vectorizer_features": 5000,
  "message": "API and model are ready for inference."
}
```

### **4ï¸âƒ£ `/info` â€” Model Metadata & Version Info**

**Method:** `GET`  
**Description:** Returns key metadata about the currently loaded model, including file size, modification date, and vectorizer stats.

```bash
curl http://127.0.0.1:8000/info
```

---

## ğŸ“‚ Project Structure

```css
sentimentsense-api/
â”œâ”€â”€ app.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â””â”€â”€ train_model.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ sentiment_model.pkl
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_texts.csv
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .dockerignore
â””â”€â”€ .gitignore

```

---

## ğŸ“œ Logging and Monitoring

Every prediction request is automatically logged to rotating files under `/logs/`.

Each log entry records:

```bash
YYYY-MM-DD HH:MM:SS | Text: <input> | Sentiment: <predicted_class>
```

Log rotation details:

- File: `logs/sentiments.log`
- Max file size: 1 MB
- Up to 3 backups are maintained (`.1`, `.2`, `.3`)

You can also view the latest predictions via API:

```bash
curl "http://127.0.0.1:8000/logs?limit=5"
```

---

## ğŸš€ Current Progress

âœ… Completed:

- Model training and hybrid prediction logic

- Working FastAPI endpoint /predict

- Successful local testing via curl

ğŸ› ï¸ Next Steps:

- Add /health route with metadata

- Train on larger dataset (IMDb or Sentiment140)

- Dockerize and deploy via AWS ECS

---

## ğŸ“… Roadmap

- [x] Project setup

- [x] Model training

- [x] API endpoint for predictions

- [x] Add logging, /logs, /health, and /info endpoints

- [ ] Containerize with Docker

- [ ] Deploy to AWS ECS

---

ğŸ‘¨â€ğŸ’» Author

- Kevin Woods
- Applied ML Engineer | AWS Certified AI Practitioner | AWS Machine Learning Certified Engineer â€“ Associate
- ğŸ”— GitHub: woodskevinj
